{"version":3,"sources":["../../../src/components/tokenizer/index.ts"],"sourcesContent":["import { createError } from '../../errors.js'\nimport { Stemmer, Tokenizer, DefaultTokenizerConfig } from '../../types.js'\nimport { replaceDiacritics } from './diacritics.js'\nimport { Language, SPLITTERS, SUPPORTED_LANGUAGES } from './languages.js'\nimport { stopWords as defaultStopWords } from './stop-words/index.js'\nimport { stemmer as english } from './english-stemmer.js'\n\ninterface DefaultTokenizer extends Tokenizer {\n  language: Language\n  stemmer?: Stemmer\n  stemmerSkipProperties: Set<string>\n  stopWords?: string[]\n  allowDuplicates: boolean\n  normalizationCache: Map<string, string>\n  normalizeToken(this: DefaultTokenizer, token: string, prop: string | undefined): string\n}\n\nfunction normalizeToken(this: DefaultTokenizer, prop: string, token: string): string {\n  const key = `${this.language}:${prop}:${token}`\n\n  if (this.normalizationCache.has(key)) {\n    return this.normalizationCache.get(key)!\n  }\n\n  // Remove stopwords if enabled\n  if (this.stopWords?.includes(token)) {\n    this.normalizationCache.set(key, '')\n    return ''\n  }\n\n  // Apply stemming if enabled\n  if (this.stemmer && !this.stemmerSkipProperties.has(prop)) {\n    token = this.stemmer(token)\n  }\n\n  token = replaceDiacritics(token)\n  this.normalizationCache.set(key, token)\n  return token\n}\n\n/* c8 ignore next 10 */\nfunction trim(text: string[]): string[] {\n  while (text[text.length - 1] === '') {\n    text.pop()\n  }\n  while (text[0] === '') {\n    text.shift()\n  }\n  return text\n}\n\nfunction tokenize(this: DefaultTokenizer, input: string, language?: string, prop?: string): string[] {\n  if (language && language !== this.language) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', language)\n  }\n\n  /* c8 ignore next 3 */\n  if (typeof input !== 'string') {\n    return [input]\n  }\n\n  const splitRule = SPLITTERS[this.language]\n  const tokens = input\n    .toLowerCase()\n    .split(splitRule)\n    .map(this.normalizeToken.bind(this, prop ?? ''))\n    .filter(Boolean)\n  const trimTokens = trim(tokens)\n\n  if (!this.allowDuplicates) {\n    return Array.from(new Set(trimTokens))\n  }\n\n  return trimTokens\n}\n\nexport async function createTokenizer(config: DefaultTokenizerConfig = {}): Promise<DefaultTokenizer> {\n  if (!config.language) {\n    config.language = 'english'\n  } else if (!SUPPORTED_LANGUAGES.includes(config.language)) {\n    throw createError('LANGUAGE_NOT_SUPPORTED', config.language)\n  }\n\n  // Handle stemming - It is disabled by default\n  let stemmer: Stemmer | undefined\n\n  if (config.stemming || (config.stemmer && !('stemming' in config))) {\n    if (config.stemmer) {\n      if (typeof config.stemmer !== 'function') {\n        throw createError('INVALID_STEMMER_FUNCTION_TYPE')\n      }\n\n      stemmer = config.stemmer\n    } else {\n      if (config.language === 'english') {\n        stemmer = english\n      } else {\n        throw createError('MISSING_STEMMER', config.language)\n      }\n    }\n  }\n\n  // Handle stopwords\n  let stopWords: string[] | undefined\n\n  if (config.stopWords !== false) {\n    stopWords = defaultStopWords[config.language] ?? []\n\n    if (Array.isArray(config.stopWords)) {\n      stopWords = config.stopWords\n    } else if (typeof config.stopWords === 'function') {\n      stopWords = await config.stopWords(stopWords)\n    } else if (config.stopWords) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n    }\n\n    // Make sure stopWords is just an array of strings\n    if (!Array.isArray(stopWords)) {\n      throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n    }\n\n    for (const s of stopWords) {\n      if (typeof s !== 'string') {\n        throw createError('CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY')\n      }\n    }\n  }\n\n  // Create the tokenizer\n  const tokenizer: DefaultTokenizer = {\n    tokenize,\n    language: config.language,\n    stemmer,\n    stemmerSkipProperties: new Set(config.stemmerSkipProperties ? [config.stemmerSkipProperties].flat() : []),\n    stopWords,\n    allowDuplicates: Boolean(config.allowDuplicates),\n    normalizeToken,\n    normalizationCache: new Map(),\n  }\n\n  tokenizer.tokenize = tokenize.bind(tokenizer)\n  tokenizer.normalizeToken = normalizeToken\n\n  return tokenizer\n}\n"],"names":["createError","replaceDiacritics","SPLITTERS","SUPPORTED_LANGUAGES","stopWords","defaultStopWords","stemmer","english","normalizeToken","prop","token","key","language","normalizationCache","has","get","includes","set","stemmerSkipProperties","trim","text","length","pop","shift","tokenize","input","splitRule","tokens","toLowerCase","split","map","bind","filter","Boolean","trimTokens","allowDuplicates","Array","from","Set","createTokenizer","config","stemming","isArray","s","tokenizer","flat","Map"],"mappings":"AAAA,SAASA,WAAW,QAAQ,kBAAiB;AAE7C,SAASC,iBAAiB,QAAQ,kBAAiB;AACnD,SAAmBC,SAAS,EAAEC,mBAAmB,QAAQ,iBAAgB;AACzE,SAASC,aAAaC,gBAAgB,QAAQ,wBAAuB;AACrE,SAASC,WAAWC,OAAO,QAAQ,uBAAsB;AAYzD,SAASC,eAAuCC,IAAY,EAAEC,KAAa,EAAU;QAQ/E;IAPJ,MAAMC,MAAM,CAAC,EAAE,IAAI,CAACC,QAAQ,CAAC,CAAC,EAAEH,KAAK,CAAC,EAAEC,MAAM,CAAC;IAE/C,IAAI,IAAI,CAACG,kBAAkB,CAACC,GAAG,CAACH,MAAM;QACpC,OAAO,IAAI,CAACE,kBAAkB,CAACE,GAAG,CAACJ;IACrC,CAAC;IAED,8BAA8B;IAC9B,IAAI,CAAA,kBAAA,IAAI,CAACP,SAAS,cAAd,6BAAA,KAAA,IAAA,gBAAgBY,SAASN,QAAQ;QACnC,IAAI,CAACG,kBAAkB,CAACI,GAAG,CAACN,KAAK;QACjC,OAAO;IACT,CAAC;IAED,4BAA4B;IAC5B,IAAI,IAAI,CAACL,OAAO,IAAI,CAAC,IAAI,CAACY,qBAAqB,CAACJ,GAAG,CAACL,OAAO;QACzDC,QAAQ,IAAI,CAACJ,OAAO,CAACI;IACvB,CAAC;IAEDA,QAAQT,kBAAkBS;IAC1B,IAAI,CAACG,kBAAkB,CAACI,GAAG,CAACN,KAAKD;IACjC,OAAOA;AACT;AAEA,qBAAqB,GACrB,SAASS,KAAKC,IAAc,EAAY;IACtC,MAAOA,IAAI,CAACA,KAAKC,MAAM,GAAG,EAAE,KAAK,GAAI;QACnCD,KAAKE,GAAG;IACV;IACA,MAAOF,IAAI,CAAC,EAAE,KAAK,GAAI;QACrBA,KAAKG,KAAK;IACZ;IACA,OAAOH;AACT;AAEA,SAASI,SAAiCC,KAAa,EAAEb,QAAiB,EAAEH,IAAa,EAAY;IACnG,IAAIG,YAAYA,aAAa,IAAI,CAACA,QAAQ,EAAE;QAC1C,MAAMZ,YAAY,0BAA0BY,UAAS;IACvD,CAAC;IAED,oBAAoB,GACpB,IAAI,OAAOa,UAAU,UAAU;QAC7B,OAAO;YAACA;SAAM;IAChB,CAAC;IAED,MAAMC,YAAYxB,SAAS,CAAC,IAAI,CAACU,QAAQ,CAAC;IAC1C,MAAMe,SAASF,MACZG,WAAW,GACXC,KAAK,CAACH,WACNI,GAAG,CAAC,IAAI,CAACtB,cAAc,CAACuB,IAAI,CAAC,IAAI,EAAEtB,QAAQ,KAC3CuB,MAAM,CAACC;IACV,MAAMC,aAAaf,KAAKQ;IAExB,IAAI,CAAC,IAAI,CAACQ,eAAe,EAAE;QACzB,OAAOC,MAAMC,IAAI,CAAC,IAAIC,IAAIJ;IAC5B,CAAC;IAED,OAAOA;AACT;AAEA,OAAO,eAAeK,gBAAgBC,SAAiC,CAAC,CAAC,EAA6B;IACpG,IAAI,CAACA,OAAO5B,QAAQ,EAAE;QACpB4B,OAAO5B,QAAQ,GAAG;IACpB,OAAO,IAAI,CAACT,oBAAoBa,QAAQ,CAACwB,OAAO5B,QAAQ,GAAG;QACzD,MAAMZ,YAAY,0BAA0BwC,OAAO5B,QAAQ,EAAC;IAC9D,CAAC;IAED,8CAA8C;IAC9C,IAAIN;IAEJ,IAAIkC,OAAOC,QAAQ,IAAKD,OAAOlC,OAAO,IAAI,CAAE,CAAA,cAAckC,MAAK,GAAK;QAClE,IAAIA,OAAOlC,OAAO,EAAE;YAClB,IAAI,OAAOkC,OAAOlC,OAAO,KAAK,YAAY;gBACxC,MAAMN,YAAY,iCAAgC;YACpD,CAAC;YAEDM,UAAUkC,OAAOlC,OAAO;QAC1B,OAAO;YACL,IAAIkC,OAAO5B,QAAQ,KAAK,WAAW;gBACjCN,UAAUC;YACZ,OAAO;gBACL,MAAMP,YAAY,mBAAmBwC,OAAO5B,QAAQ,EAAC;YACvD,CAAC;QACH,CAAC;IACH,CAAC;IAED,mBAAmB;IACnB,IAAIR;IAEJ,IAAIoC,OAAOpC,SAAS,KAAK,KAAK,EAAE;QAC9BA,YAAYC,gBAAgB,CAACmC,OAAO5B,QAAQ,CAAC,IAAI,EAAE;QAEnD,IAAIwB,MAAMM,OAAO,CAACF,OAAOpC,SAAS,GAAG;YACnCA,YAAYoC,OAAOpC,SAAS;QAC9B,OAAO,IAAI,OAAOoC,OAAOpC,SAAS,KAAK,YAAY;YACjDA,YAAY,MAAMoC,OAAOpC,SAAS,CAACA;QACrC,OAAO,IAAIoC,OAAOpC,SAAS,EAAE;YAC3B,MAAMJ,YAAY,+CAA8C;QAClE,CAAC;QAED,kDAAkD;QAClD,IAAI,CAACoC,MAAMM,OAAO,CAACtC,YAAY;YAC7B,MAAMJ,YAAY,+CAA8C;QAClE,CAAC;QAED,KAAK,MAAM2C,KAAKvC,UAAW;YACzB,IAAI,OAAOuC,MAAM,UAAU;gBACzB,MAAM3C,YAAY,+CAA8C;YAClE,CAAC;QACH;IACF,CAAC;IAED,uBAAuB;IACvB,MAAM4C,YAA8B;QAClCpB;QACAZ,UAAU4B,OAAO5B,QAAQ;QACzBN;QACAY,uBAAuB,IAAIoB,IAAIE,OAAOtB,qBAAqB,GAAG;YAACsB,OAAOtB,qBAAqB;SAAC,CAAC2B,IAAI,KAAK,EAAE;QACxGzC;QACA+B,iBAAiBF,QAAQO,OAAOL,eAAe;QAC/C3B;QACAK,oBAAoB,IAAIiC;IAC1B;IAEAF,UAAUpB,QAAQ,GAAGA,SAASO,IAAI,CAACa;IACnCA,UAAUpC,cAAc,GAAGA;IAE3B,OAAOoC;AACT,CAAC"}